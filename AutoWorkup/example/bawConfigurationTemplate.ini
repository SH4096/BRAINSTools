#################################################################
### Inspect carefully...
### - ${} part and replace with something for your won
### - _BUILD_DIR
### - VIRTUALENV_DIR
###
#################################################################

[EXPERIMENT]
SESSION_DB_BASE=${full_path_to_filename}/list.csv
##--------------------------------------------------------------
## Example of 'list.csv' file:
##  "project","subjectID_A","sessionID","{'T1-30':['path/subjectID_A_sessionID_T1_COR.nii.gz'],'T2-30':['path/subjectID_A_sessionID_T2_COR.nii.gz']}"
##  "project","subjectID_A","sessionID2","{'T1-30':['path/subjectID_A_sessionID2_T1_COR.nii.gz', 'path/subjectID_A_sessionID2_T1_COR_REP1.nii.gz'],'T2-30':['path/subjectID_A_sessionID2_T2_COR.nii.gz']}"
##--------------------------------------------------------------
SESSION_DB_TEMP=%(SESSION_DB_BASE)s
SESSION_DB_LONG=%(SESSION_DB_BASE)s

EXPERIMENT_BASE=${YYYYMMDD_ProjectName}_base
EXPERIMENT_TEMP=${YYYYMMDD_ProjectName}_temp
EXPERIMENT_LONG=${YYYYMMDD_ProjectName}_long

EXPERIMENT_TEMP_INPUT=%(EXPERIMENT_BASE)s
EXPERIMENT_LONG_INPUT=%(EXPERIMENT_TEMP)s

WORKFLOW_COMPONENTS_BASE=['denoise','landmark','auxlmk','tissue_classify','warp_atlas_to_subject','malf_2015_wholebrain']
WORKFLOW_COMPONENTS_TEMP=[]
WORKFLOW_COMPONENTS_LONG=['denoise','landmark','auxlmk','tissue_classify','malf_2015_wholebrain']

BASE_OUTPUT_DIR=/Shared/sinapse/CACHE/
ATLAS_PATH=path_to_namic_build/bin/Atlas/Atlas_20131115
JointFusion_ATLAS_DB_BASE=path_to_atlas_listFile/baw20150709WholeBrainAtlasList.csv
##--------------------------------------------------------------
## * JointFusion_ATLAS_DB_BASE only requires if you choose to run
##     'malf_2015_wholebrain' in the 'WORKFLOW_COMPONENET_XXXX'
##     as appeared in the above.
##
## * JointFusion_ATLAS_DB_BASE 'baw20150709WholeBrainAtlasList.csv' file example,
## "atlasID_A", {'t1':'path/atlasID_A/t1.nii.gz','t2':'path/atlasID_A/t2.nii.gz','label':'path/atlasID_A/wholeBrainLabel.nii.gz','lmks':'path/atlasID_A/BCD_ACPC_Landmarks.fcsv'}
## "atlasID_B", {'t1':'path/atlasID_B/t1.nii.gz','t2':'path/atlasID_B/t2.nii.gz','label':'path/atlasID_B/wholeBrainLabel.nii.gz','lmks':'path/atlasID_B/BCD_ACPC_Landmarks.fcsv'}
##--------------------------------------------------------------
RELABEL2LOBES_FILENAME=path_to_atlas_listFile/Label2Lobes.csv
##--------------------------------------------------------------
## RELABEL2LOBES file example
##  #originalLabel,originalLabelName,targetLabel,targetLabelName
##  1005,ctx-lh-cuneus,1005,crt-lh-occipital
##  1006,ctx-lh-entorhinal,1006,crt-lh-temporal
##  1007,ctx-lh-fusiform,1006,crt-lh-temporal
##  1008,ctx-lh-inferiorparietal,1008,crt-lh-parietal
##  1009,ctx-lh-inferiortemporal,1006,crt-lh-temporal
##  1011,ctx-lh-lateraloccipital,1005,crt-lh-occipital
##--------------------------------------------------------------

[NIPYPE]
GLOBAL_DATA_SINK_REWRITE=False
#GLOBAL_DATA_SINK_REWRITE=True

#################################################################
# Below contains an OS specific experiment setting to
#     run BRAINSTools Auto Workup.
# You can sepcify as many OS-dependent environments as
#     you want but you MAY CHOOSE ONLY ONE of followings
#     when you run.
#################################################################
[OSX]
###
### Configuration Example for OS-X
###

## The cluster queue to use for submitting "normal running" jobs.
QUEUE=-q all
## The cluster queue to use for submitting "long running" jobs.
QUEUE_LONG=-q all
# The QSTAT command for immediate update of values [ use 'qstat' if in doubt ]
QSTAT_IMMEDIATE=qstat
QSTAT_CACHED=qstat
## Necessary modules to load for jobs
MODULES=[]

_GRAPHVIZ_BIN=/usr/bin/graphviz
VIRTUALENV_DIR=/Shared/sinapse/scratch/eunyokim/src/BAWPythonEnv/MacEnv/
# NAMICExternalProjects build tree
_BUILD_DIR=/Shared/sinapse/scratch/eunyokim/src/NamicExternal/build_OSX_20150619/
_BRAINSTOOLS_BIN_DIR=%(_BUILD_DIR)s/bin
_SIMPLEITK_PYTHON_LIB=%(_BUILD_DIR)s/lib

_SIMPLEITK_PACKAGE_DIR=%(_BUILD_DIR)s/SimpleITK-build/Wrapping
_NIPYPE_PACKAGE_DIR=%(_BUILD_DIR)s/NIPYPE
############## -- You should not need to modify below here. ###########
APPEND_PYTHONPATH=%(_NIPYPE_PACKAGE_DIR)s:%(_SIMPLEITK_PYTHON_LIB)s:%(_SIMPLEITK_PACKAGE_DIR)s
APPEND_PATH=%(_BRAINSTOOLS_BIN_DIR)s:%(_SIMPLEITK_PYTHON_LIB)s:%(_GRAPHVIZ_BIN)s

[RHEL5]
###
### Configuration Example for Red Hat Enterprize Linux 5
###
## The cluster queue to use for submitting "normal running" jobs.
QUEUE=-q ICTS
## The cluster queue to use for submitting "long running" jobs.
QUEUE_LONG=-q ICTS
# The QSTAT command for immediate update of values [ use 'qstat' if in doubt ]
QSTAT_IMMEDIATE=qstat
QSTAT_CACHED=qstat
## The QSTAT command for cached update of values ( to take load off of OGE server during heavy job usage ) [ use 'qstat' if in doubt ]
#
# QSTAT_IMMEDIATE_EXE=/Shared/johnsonhj/HDNI/20140219_AutoWorkupTest/scripts/qstat_immediate.sh
# QSTAT_CACHED_EXE=/Shared/johnsonhj/HDNI/20140219_AutoWorkupTest/scripts/qstat_cached.sh

## Necessary modules to load for jobs
MODULES=['python/2.7','gcc/4.8.2']

_GRAPHVIZ_BIN=/usr/bin/graphviz
VIRTUALENV_DIR=/Shared/sinapse/sharedopt/20140926/RHEL5/python_HD/
# NAMICExternalProjects build tree
_BUILD_DIR=/Shared/sinapse/sharedopt/20140926/RHEL5/NAMIC-build
_BRAINSTOOLS_BIN_DIR=%(_BUILD_DIR)s/bin
_SIMPLEITK_PYTHON_LIB=%(_BUILD_DIR)s/lib

[DEFAULT]
# The prefix to add to all image files in the $(SESSION_DB) to account for different file system mount points
MOUNT_PREFIX=
MODULES=
